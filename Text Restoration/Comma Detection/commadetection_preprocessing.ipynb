{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['emma<NOUN>', 'by<ADP>', 'jane<NOUN>', 'austen<ADJ>', 'volume<NOUN>', 'i<VERB>', 'chapter<NOUN>', 'i<NOUN>', 'emma<VERB>', 'woodhouse<NOUN>']\n"
     ]
    }
   ],
   "source": [
    "# import nltk and gutenberg\n",
    "# from nltk import necessary tool\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import gutenberg as gb\n",
    "\n",
    "# store sentences of \"Emma\" in variable\n",
    "emma = gb.sents('austen-emma.txt')\n",
    "\n",
    "stext = ''\n",
    "\n",
    "# store punctuation that still is in story_merged in variable\n",
    "punc = ['.', ',', '-', ';', '(', ')']\n",
    "\n",
    "# go through each sentence in emma\n",
    "for sent in emma:\n",
    "    # go through each word in the sentences\n",
    "    for word in sent:\n",
    "        flag = True\n",
    "        # go throug each character in the word\n",
    "        for char in word:\n",
    "            # check whether character is not alphabetical and not in punc \n",
    "            if not char.isalpha() and not char in punc:\n",
    "                flag = False\n",
    "                break\n",
    "        # if character is alphabetical or in pun it is added to stext variable\n",
    "        if flag:\n",
    "            stext += word.lower() + ' '\n",
    "\n",
    "# tokenizing each word within stext\n",
    "emma_tokens = word_tokenize(stext)\n",
    "\n",
    "# adding pos-tags to each tokenized word\n",
    "emma_poslist = nltk.pos_tag(emma_tokens, tagset='universal')\n",
    "\n",
    "emma_pos = []\n",
    "temp = []\n",
    "i = 0\n",
    "# going through the pos-tags (is a list with lots of tuples)\n",
    "# adding word and then pos-tags in '<' '>' to list\n",
    "for item in emma_poslist:\n",
    "    temp = []\n",
    "    temp.append(item[0])\n",
    "    temp.append('<')\n",
    "    temp.append(item[1])\n",
    "    temp.append('>')\n",
    "    emma_pos.append(''.join(temp))\n",
    "    \n",
    "# the output then looks like this\n",
    "print(emma_pos[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-1b42cdb247ec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0;31m# if the next word is a tagged comma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0;31m# write a 1 in the response column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0memma_pos\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m',<.>'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m             \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\t1\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# opening a new file\n",
    "f = open(\"emma_pos_comma_sbd_in.txt\", \"w+\")\n",
    "\n",
    "# storing placeholders in variables\n",
    "cm15, cm14, cm13, cm12, cm11,\\\n",
    "cm10, cm9, cm8, cm7, cm6, cm5, cm4, cm3, cm2, cm1 = \\\n",
    "'+', '+', '+', '+', '+',\\\n",
    "'+', '+', '+', '+', '+', '+', '+', '+', '+', '+'\n",
    "\n",
    "# going through each word\n",
    "# printing the placeholders followed by tabs\n",
    "# only doing to if the word is not a tagged comma\n",
    "for i, word in enumerate(emma_pos):\n",
    "    if word != ',<.>':\n",
    "        f.write(cm15 + '\\t')\n",
    "        f.write(cm14 + '\\t')\n",
    "        f.write(cm13 + '\\t')\n",
    "        f.write(cm12 + '\\t')\n",
    "        f.write(cm11 + '\\t')\n",
    "        f.write(cm10 + '\\t')\n",
    "        f.write(cm9 + '\\t')\n",
    "        f.write(cm8 + '\\t')\n",
    "        f.write(cm7 + '\\t')\n",
    "        f.write(cm6 + '\\t')\n",
    "        f.write(cm5 + '\\t')\n",
    "        f.write(cm4 + '\\t')\n",
    "        f.write(cm3 + '\\t')\n",
    "        f.write(cm2 + '\\t')\n",
    "        f.write(cm1 + '\\t')\n",
    "        c = 15\n",
    "        x = i\n",
    "        \n",
    "        # as long as the word is not a tagged comma:\n",
    "        while c < 16:\n",
    "            if emma_pos[x] != ',<.>':\n",
    "                f.write(emma_pos[x]) #write the word\n",
    "                c += 1 # increase counter by 1\n",
    "            x += 1     # increase index by 1\n",
    "        \n",
    "        # if the next word is a tagged comma\n",
    "        # write a 1 in the response column\n",
    "        if emma_pos[i+1] == ',<.>':\n",
    "            f.write('\\t1\\n')\n",
    "            \n",
    "        # if the next word is not a comma\n",
    "        # write a 0 in the response column\n",
    "        else:\n",
    "            f.write('\\t0\\n')\n",
    "        \n",
    "        # slowly exchance all the placeholders\n",
    "        # word by word each time to create the sliding window\n",
    "        cm15 = cm14\n",
    "        cm14 = cm13\n",
    "        cm13 = cm12\n",
    "        cm12 = cm11\n",
    "        cm11 = cm10\n",
    "        cm10 = cm9\n",
    "        cm9 = cm8\n",
    "        cm8 = cm7\n",
    "        cm7 = cm6\n",
    "        cm6 = cm5\n",
    "        cm5 = cm4\n",
    "        cm4 = cm3\n",
    "        cm3 = cm2\n",
    "        cm2 = cm1\n",
    "        cm1 = word\n",
    "\n",
    "# close the file\n",
    "f.close()\n",
    "\n",
    "# the programm will give an error, however that can be ignored\n",
    "# the output file is correct and can be used\n",
    "# the index happens because of line 41 where we check for i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open the sentence boundary detection out file\n",
    "# storing the data in a string variable\n",
    "with open('sentence_boundary_detection_out.txt', 'r') as file:\n",
    "    data = file.read().replace('\\n', ' ')\n",
    "\n",
    "# tokenizing each word in the string\n",
    "data_tokens = word_tokenize(data)\n",
    "\n",
    "# tagging each word in the tokenized list\n",
    "story_poslist = nltk.pos_tag(data_tokens, tagset='universal')\n",
    "\n",
    "story_pos = []\n",
    "# going through the pos-tags (is a list with lots of tuples)\n",
    "# adding word and then pos-tags in '<' '>' to list\n",
    "for item in story_poslist:\n",
    "    temp = []\n",
    "    temp.append(item[0])\n",
    "    temp.append('<')\n",
    "    temp.append(item[1])\n",
    "    temp.append('>')\n",
    "    story_pos.append(''.join(temp))\n",
    "    \n",
    "# opening a new file that will contain the sliding window\n",
    "f = open(\"emma_commadetection_in.txt\", \"w+\")\n",
    "\n",
    "# storing placeholders in variables\n",
    "cm15, cm14, cm13, cm12, cm11,\\\n",
    "cm10, cm9, cm8, cm7, cm6, cm5, cm4, cm3, cm2, cm1 = \\\n",
    "'+', '+', '+', '+', '+',\\\n",
    "'+', '+', '+', '+', '+', '+', '+', '+', '+', '+'\n",
    "\n",
    "# going through each word\n",
    "# printing the placeholders followed by tabs \n",
    "for i, word in enumerate(story_pos):\n",
    "        f.write(cm15 + '\\t')\n",
    "        f.write(cm14 + '\\t')\n",
    "        f.write(cm13 + '\\t')\n",
    "        f.write(cm12 + '\\t')\n",
    "        f.write(cm11 + '\\t')\n",
    "        f.write(cm10 + '\\t')\n",
    "        f.write(cm9 + '\\t')\n",
    "        f.write(cm8 + '\\t')\n",
    "        f.write(cm7 + '\\t')\n",
    "        f.write(cm6 + '\\t')\n",
    "        f.write(cm5 + '\\t')\n",
    "        f.write(cm4 + '\\t')\n",
    "        f.write(cm3 + '\\t')\n",
    "        f.write(cm2 + '\\t')\n",
    "        f.write(cm1 + '\\t')\n",
    "        c = 15\n",
    "        x = i\n",
    "        \n",
    "        # writing the word in the file\n",
    "        while c < 16:\n",
    "            f.write(story_pos[x])\n",
    "            f.write('\\n')\n",
    "            c += 1\n",
    "            x += 1\n",
    "\n",
    "        # slowly exchance all the placeholders\n",
    "        # word by word each time to create the sliding window    \n",
    "        cm15 = cm14\n",
    "        cm14 = cm13\n",
    "        cm13 = cm12\n",
    "        cm12 = cm11\n",
    "        cm11 = cm10\n",
    "        cm10 = cm9\n",
    "        cm9 = cm8\n",
    "        cm8 = cm7\n",
    "        cm7 = cm6\n",
    "        cm6 = cm5\n",
    "        cm5 = cm4\n",
    "        cm4 = cm3\n",
    "        cm3 = cm2\n",
    "        cm2 = cm1\n",
    "        cm1 = word\n",
    "\n",
    "# closing the file\n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
